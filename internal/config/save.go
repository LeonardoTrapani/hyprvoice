package config

import (
	"fmt"
	"os"
)

func SaveDefaultConfig() error {
	configPath, err := GetConfigPath()
	if err != nil {
		return err
	}

	file, err := os.Create(configPath)
	if err != nil {
		return fmt.Errorf("failed to create config file: %w", err)
	}
	defer file.Close()

	configContent := `# Hyprvoice Configuration
# This file is automatically generated with defaults.
# Edit values as needed - changes are applied immediately without daemon restart.
#
# MIGRATION NOTE: If upgrading from an older version, your transcription.api_key
# will be automatically migrated to the new [providers.X] format. Run 'hyprvoice configure'
# to update your config file structure.

# Keywords help both transcription and LLM understand domain-specific terms
# Add names, technical terms, or brand names that might be misheard
keywords = []

# ─────────────────────────────────────────────────────────────────────────────
# Provider API Keys
# Configure API keys for each provider you want to use.
# Keys can also be set via environment variables: OPENAI_API_KEY, GROQ_API_KEY, etc.
# ─────────────────────────────────────────────────────────────────────────────

[providers.openai]
  api_key = ""                 # OpenAI API key (or set OPENAI_API_KEY env var)

[providers.groq]
  api_key = ""                 # Groq API key (or set GROQ_API_KEY env var)

# Uncomment to configure additional providers:
# [providers.mistral]
#   api_key = ""               # Mistral API key (or set MISTRAL_API_KEY env var)
# [providers.elevenlabs]
#   api_key = ""               # ElevenLabs API key (or set ELEVENLABS_API_KEY env var)
# [providers.deepgram]
#   api_key = ""               # Deepgram API key (or set DEEPGRAM_API_KEY env var)

# ─────────────────────────────────────────────────────────────────────────────
# Audio Recording
# ─────────────────────────────────────────────────────────────────────────────

[recording]
  sample_rate = 16000          # Audio sample rate in Hz (16000 recommended for speech)
  channels = 1                 # Number of audio channels (1 = mono, 2 = stereo)
  format = "s16"               # Audio format (s16 = 16-bit signed integers)
  buffer_size = 8192           # Internal buffer size in bytes (larger = less CPU, more latency)
  device = ""                  # PipeWire audio device (empty = use default microphone)
  channel_buffer_size = 30     # Audio frame buffer size (frames to buffer)
  timeout = "5m"               # Maximum recording duration (e.g., "30s", "2m", "5m")

# ─────────────────────────────────────────────────────────────────────────────
# Speech Transcription
# Converts audio to text using speech-to-text APIs
# ─────────────────────────────────────────────────────────────────────────────

[transcription]
  provider = "openai"          # "openai", "groq-transcription", "groq-translation", "mistral-transcription", "elevenlabs", "whisper-cpp"
  language = ""                # Language code (empty = auto-detect, "en", "it", "es", "fr", etc.)
  model = "whisper-1"          # Model: OpenAI="whisper-1", Groq="whisper-large-v3", Mistral="voxtral-mini-latest", ElevenLabs="scribe_v1"
  threads = 0                  # CPU threads for local transcription (0 = auto: uses NumCPU-1)

# ─────────────────────────────────────────────────────────────────────────────
# LLM Post-Processing (Recommended)
# Cleans up transcribed text: removes stutters, adds punctuation, fixes grammar
# ─────────────────────────────────────────────────────────────────────────────

[llm]
  enabled = true               # Enable LLM post-processing (highly recommended)
  provider = "openai"          # "openai" or "groq" (must have API key configured above)
  model = "gpt-4o-mini"        # OpenAI: "gpt-4o-mini", Groq: "llama-3.3-70b-versatile"

[llm.post_processing]
  remove_stutters = true       # Remove "um", "uh", repeated words
  add_punctuation = true       # Add proper punctuation
  fix_grammar = true           # Fix grammatical errors
  remove_filler_words = true   # Remove "like", "you know", "basically"

[llm.custom_prompt]
  enabled = false              # Enable custom instructions for LLM
  prompt = ""                  # Additional instructions (e.g., "Format as bullet points")

# ─────────────────────────────────────────────────────────────────────────────
# Text Injection
# How transcribed text is inserted into applications
# ─────────────────────────────────────────────────────────────────────────────

[injection]
  backends = ["ydotool", "wtype", "clipboard"]  # Ordered fallback chain (tries each until one succeeds)
  ydotool_timeout = "5s"       # Timeout for ydotool commands
  wtype_timeout = "5s"         # Timeout for wtype commands
  clipboard_timeout = "3s"     # Timeout for clipboard operations

# ─────────────────────────────────────────────────────────────────────────────
# Desktop Notifications
# ─────────────────────────────────────────────────────────────────────────────

[notifications]
  enabled = true               # Enable desktop notifications
  type = "desktop"             # "desktop", "log", or "none"

  # Custom notification messages (optional - defaults shown below)
  # Uncomment and modify to customize notification text
  # [notifications.messages]
  #   [notifications.messages.recording_started]
  #     title = "Hyprvoice"
  #     body = "Recording Started"
  #   [notifications.messages.transcribing]
  #     title = "Hyprvoice"
  #     body = "Recording Ended... Transcribing"
  #   [notifications.messages.llm_processing]
  #     title = "Hyprvoice"
  #     body = "Processing..."
  #   [notifications.messages.config_reloaded]
  #     title = "Hyprvoice"
  #     body = "Config Reloaded"
  #   [notifications.messages.operation_cancelled]
  #     title = "Hyprvoice"
  #     body = "Operation Cancelled"
  #   [notifications.messages.recording_aborted]
  #     body = "Recording Aborted"
  #   [notifications.messages.injection_aborted]
  #     body = "Injection Aborted"
  #
  # Emoji-only example (for minimal pill-style notifications):
  #   [notifications.messages.recording_started]
  #     title = ""
  #     body = "..."

# ─────────────────────────────────────────────────────────────────────────────
# Reference: Provider Details
# ─────────────────────────────────────────────────────────────────────────────
#
# Transcription providers:
# - "openai": OpenAI Whisper API (cloud-based, excellent accuracy)
# - "groq-transcription": Groq Whisper API (very fast, models: whisper-large-v3, whisper-large-v3-turbo)
# - "groq-translation": Groq translation to English (always outputs English text, model: whisper-large-v3)
# - "mistral-transcription": Mistral Voxtral API (excellent for European languages, model: voxtral-mini-latest)
# - "elevenlabs": ElevenLabs Scribe API (99 languages, models: scribe_v1, scribe_v2)
#
# LLM providers (for post-processing):
# - "openai": GPT models (gpt-4o-mini recommended for cost/quality balance)
# - "groq": Fast inference (llama-3.3-70b-versatile recommended)
#
# Injection backends:
# - "ydotool": Uses ydotool (requires ydotoold daemon). Best for Chromium/Electron apps.
# - "wtype": Uses wtype for Wayland. May have issues with some Chromium apps.
# - "clipboard": Copies to clipboard only (most reliable, requires manual paste).
#
# Language codes: "" (auto-detect), "en", "it", "es", "fr", "de", "pt", etc.
`

	if _, err := file.WriteString(configContent); err != nil {
		return fmt.Errorf("failed to write config content: %w", err)
	}

	return nil
}
